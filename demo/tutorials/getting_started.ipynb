{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multiview Dataset Generator Demo\n",
    "\n",
    "Once you have [installed](https://gitlab.lis-lab.fr/dev/multiview_generator) MAGE, you are able to run it with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:27:21.327351Z",
     "start_time": "2025-07-25T16:27:21.325564Z"
    }
   },
   "source": [
    "from multiview_generator.gaussian_classes import MultiViewGaussianSubProblemsGenerator\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "random_state = np.random.RandomState(42)"
   ],
   "outputs": [],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic configuration\n",
    "\n",
    "Let us suppose that you want to build a multiview dataset with 4 views and three classes : "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:27:21.340800Z",
     "start_time": "2025-07-25T16:27:21.339347Z"
    }
   },
   "source": [
    "name = \"demo\"\n",
    "n_views = 4\n",
    "n_classes = 3"
   ],
   "outputs": [],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to configure the dataset, you have to provide the error matrix that gives the expected error of the Byaes classifier for Class i on View j as the value in row i column j :  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:27:21.390817Z",
     "start_time": "2025-07-25T16:27:21.388796Z"
    }
   },
   "source": [
    "error_matrix = [\n",
    "   [0.30, 0.32, 0.38, 0.30],\n",
    "   [0.35, 0.28, 0.20, 0.15],\n",
    "   [0.25, 0.29, 0.15, 0.21]\n",
    "]\n",
    "print(tabulate(error_matrix, tablefmt=\"grid\"))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+------+------+\n",
      "| 0.3  | 0.32 | 0.38 | 0.3  |\n",
      "+------+------+------+------+\n",
      "| 0.35 | 0.28 | 0.2  | 0.15 |\n",
      "+------+------+------+------+\n",
      "| 0.25 | 0.29 | 0.15 | 0.21 |\n",
      "+------+------+------+------+\n"
     ]
    }
   ],
   "execution_count": 108
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once this has been defined, you can set all the other parameters of the dataset : \n",
    "* the number of samples, \n",
    "* the number of features of each view,\n",
    "* the proportion of samples in each class."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:31:59.194366Z",
     "start_time": "2025-07-25T16:27:21.436218Z"
    }
   },
   "source": [
    "n_samples = 2000\n",
    "n_features = 3\n",
    "class_weights = [0.333, 0.333, 0.333,]"
   ],
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate the dataset\n",
    "\n",
    "With the basic configuration done, we can generate the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:04.526096Z",
     "start_time": "2025-07-25T16:32:04.402520Z"
    }
   },
   "source": [
    "generator = MultiViewGaussianSubProblemsGenerator(name=name, n_views=n_views, \n",
    "                                          n_classes=n_classes, \n",
    "                                          n_samples=n_samples, \n",
    "                                          n_features=n_features, \n",
    "                                          class_weights=class_weights, \n",
    "                                          error_matrix=error_matrix, \n",
    "                                          random_state=random_state)  \n",
    "\n",
    "dataset, y = generator.generate_multi_view_dataset()\n",
    "\n",
    "for view_index, view_data in enumerate(dataset):\n",
    "    print(\"View {} of shape {}\".format(view_index+1, view_data.shape))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 1 of shape (1998, 3)\n",
      "View 2 of shape (1998, 3)\n",
      "View 3 of shape (1998, 3)\n",
      "View 4 of shape (1998, 3)\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we see that the output shape is 1998 instead of 1000 as the classes are supposed to be equivalent. \n",
    "\n",
    "## Get a description of it\n",
    "\n",
    "Now, if you wish to get information about the generated dataset, run : "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:04.573705Z",
     "start_time": "2025-07-25T16:32:04.537628Z"
    }
   },
   "source": [
    "description = generator.gen_report(save=False)"
   ],
   "outputs": [],
   "execution_count": 124
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This will generate a markdown report on the dataset. Here, we used `save=False` so the description is not saved in a file. \n",
    "\n",
    "To print it in this notebook, we use : "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:04.592475Z",
     "start_time": "2025-07-25T16:32:04.590106Z"
    }
   },
   "source": [
    "from IPython.display import display,Markdown\n",
    "display(Markdown(description))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ],
      "text/markdown": "# Generated dataset description\n\nThe dataset named `demo` has been generated by [MAGE](https://gitlab.lis-lab.fr/dev/multiview_generator) and is comprised of \n\n* 1998 samples, splitted in \n* 3 classes, described by \n* 4 views.\n\nThe input error matrix is \n \n|         |   View 1 |   View 2 |   View 3 |   View 4 |\n|---------|----------|----------|----------|----------|\n| Class 1 |     0.3  |     0.32 |     0.38 |     0.3  |\n| Class 2 |     0.35 |     0.28 |     0.2  |     0.15 |\n| Class 3 |     0.25 |     0.29 |     0.15 |     0.21 |\n\n The classes are balanced as : \n\n* Class 1 : 666 samples (33% of the dataset)\n* Class 2 : 666 samples (33% of the dataset)\n* Class 3 : 666 samples (33% of the dataset)\n\n The views have \n\n* 64.56% redundancy, \n* 1.0% mutual error and \n* 34.53% complementarity with a level of [[3]\n [3]\n [3]].\n\n## Views description\n\n### View 1\n\nThis view is generated with StumpsGenerator, with the following configuration : \n```yaml\nclass_sep: 1.0\nn_clusters_per_class: 1\nn_features: 3\n```\n\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\n\n Its empirical bayesian classifier is a decision stump\n\n### View 2\n\nThis view is generated with StumpsGenerator, with the following configuration : \n```yaml\nclass_sep: 1.0\nn_clusters_per_class: 1\nn_features: 3\n```\n\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\n\n Its empirical bayesian classifier is a decision stump\n\n### View 3\n\nThis view is generated with StumpsGenerator, with the following configuration : \n```yaml\nclass_sep: 1.0\nn_clusters_per_class: 1\nn_features: 3\n```\n\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\n\n Its empirical bayesian classifier is a decision stump\n\n### View 4\n\nThis view is generated with StumpsGenerator, with the following configuration : \n```yaml\nclass_sep: 1.0\nn_clusters_per_class: 1\nn_features: 3\n```\n\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\n\n Its empirical bayesian classifier is a decision stump\n\n## Statistical analysis\n\nBayes error matrix : \n\n|        |   Class 1 |   Class 2 |   Class 3 |\n|--------|-----------|-----------|-----------|\n| View 1 |  0.328829 |  0.334835 |  0.25976  |\n| View 2 |  0.33033  |  0.282282 |  0.283784 |\n| View 3 |  0.369369 |  0.198198 |  0.126126 |\n| View 4 |  0.310811 |  0.141141 |  0.189189 |\n\n The error, as computed by the 'empirical bayes' classifier of each view : \n\n|        |   Class 1 |   Class 2 |   Class 3 |\n|--------|-----------|-----------|-----------|\n| View 1 |  0.304805 |  0.297297 | 0.363363  |\n| View 2 |  0.325826 |  0.280781 | 0.219219  |\n| View 3 |  0.381381 |  0.160661 | 0.0975976 |\n| View 4 |  0.279279 |  0.148649 | 0.171171  |\n\nThis report has been automatically generated on July 25, 2025 at 18:32:04"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 125
  },
  {
   "metadata": {
    "nbsphinx": "hidden",
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:04.701481Z",
     "start_time": "2025-07-25T16:32:04.698357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "dir_path = os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "if os.environ.get(\"SPHINX_BUILD\") == \"1\":\n",
    "    supp_dir = os.path.join(\"_static\", \"supplementary_material\")\n",
    "else:\n",
    "    supp_dir = os.path.join(\"supplementary_material\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "supp_dir =  supplementary_material\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": "But if you just want to save it, you can use :"
  },
  {
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:04.905372Z",
     "start_time": "2025-07-25T16:32:04.726773Z"
    }
   },
   "cell_type": "code",
   "source": "generator.gen_report(output_path=supp_dir, save=True)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Generated dataset description\\n\\nThe dataset named `demo` has been generated by [MAGE](https://gitlab.lis-lab.fr/dev/multiview_generator) and is comprised of \\n\\n* 1998 samples, splitted in \\n* 3 classes, described by \\n* 4 views.\\n\\nThe input error matrix is \\n \\n|         |   View 1 |   View 2 |   View 3 |   View 4 |\\n|---------|----------|----------|----------|----------|\\n| Class 1 |     0.3  |     0.32 |     0.38 |     0.3  |\\n| Class 2 |     0.35 |     0.28 |     0.2  |     0.15 |\\n| Class 3 |     0.25 |     0.29 |     0.15 |     0.21 |\\n\\n The classes are balanced as : \\n\\n* Class 1 : 666 samples (33% of the dataset)\\n* Class 2 : 666 samples (33% of the dataset)\\n* Class 3 : 666 samples (33% of the dataset)\\n\\n The views have \\n\\n* 64.56% redundancy, \\n* 1.0% mutual error and \\n* 34.53% complementarity with a level of [[3]\\n [3]\\n [3]].\\n\\n## Views description\\n\\n### View 1\\n\\nThis view is generated with StumpsGenerator, with the following configuration : \\n```yaml\\nclass_sep: 1.0\\nn_clusters_per_class: 1\\nn_features: 3\\n```\\n\\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\\n\\n Its empirical bayesian classifier is a decision stump\\n\\n### View 2\\n\\nThis view is generated with StumpsGenerator, with the following configuration : \\n```yaml\\nclass_sep: 1.0\\nn_clusters_per_class: 1\\nn_features: 3\\n```\\n\\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\\n\\n Its empirical bayesian classifier is a decision stump\\n\\n### View 3\\n\\nThis view is generated with StumpsGenerator, with the following configuration : \\n```yaml\\nclass_sep: 1.0\\nn_clusters_per_class: 1\\nn_features: 3\\n```\\n\\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\\n\\n Its empirical bayesian classifier is a decision stump\\n\\n### View 4\\n\\nThis view is generated with StumpsGenerator, with the following configuration : \\n```yaml\\nclass_sep: 1.0\\nn_clusters_per_class: 1\\nn_features: 3\\n```\\n\\nThis view has 3 features, among which 2 are relevant for classification (they are the 2 first columns of the view) the other are filled with uniform noise.\\n\\n Its empirical bayesian classifier is a decision stump\\n\\n## Statistical analysis\\n\\nBayes error matrix : \\n\\n|        |   Class 1 |   Class 2 |   Class 3 |\\n|--------|-----------|-----------|-----------|\\n| View 1 |  0.328829 |  0.334835 |  0.25976  |\\n| View 2 |  0.33033  |  0.282282 |  0.283784 |\\n| View 3 |  0.369369 |  0.198198 |  0.126126 |\\n| View 4 |  0.310811 |  0.141141 |  0.189189 |\\n\\n The error, as computed by the 'empirical bayes' classifier of each view : \\n\\n|        |   Class 1 |   Class 2 |   Class 3 |\\n|--------|-----------|-----------|-----------|\\n| View 1 |  0.304805 |  0.297297 | 0.363363  |\\n| View 2 |  0.325826 |  0.280781 | 0.219219  |\\n| View 3 |  0.381381 |  0.160661 | 0.0975976 |\\n| View 4 |  0.279279 |  0.148649 | 0.171171  |\\n\\nThis report has been automatically generated on July 25, 2025 at 18:32:04\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 127
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This will save the description in the current directory, in a file called `demo.md` as the name of the dataset is \"demo\".\n",
    "\n",
    "## Save the dataset in an HDF5 file \n",
    "\n",
    "Moreover, it is possible to save tha dataset in an HDF5 file, compatible with [SuMMIT](https://gitlab.lis-lab.fr/baptiste.bauvin/summit/) with \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:04.975745Z",
     "start_time": "2025-07-25T16:32:04.911534Z"
    }
   },
   "source": "generator.to_hdf5_mc(saving_path=supp_dir)",
   "outputs": [],
   "execution_count": 128
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing the dataset with [plotly](https://plotly.com/)\n",
    "\n",
    "Here, we purposely used only 3 featrues per view, so the generated dataset is easily plottable in 3D. \n",
    "\n",
    "Let us plot each view :"
   ]
  },
  {
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:05.071110Z",
     "start_time": "2025-07-25T16:32:04.983294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "from IPython.display import display\n",
    "from IPython.display import IFrame\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles= [\"View {}\".format(view_index)\n",
    "                                     for view_index in range(n_views)],\n",
    "                    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}, ],\n",
    "                               [{'type': 'scatter3d'},\n",
    "                                {'type': 'scatter3d'}, ]])\n",
    "row = 1\n",
    "col = 1\n",
    "show_legend = True\n",
    "# Plot the data for each view and each label\n",
    "for view_index in range(n_views):\n",
    "    for lab_index in range(n_classes):\n",
    "        concerned_examples = np.where(generator.y == lab_index)[0]\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=generator.dataset[view_index][concerned_examples, 0],\n",
    "                y=generator.dataset[view_index][concerned_examples, 1],\n",
    "                z=generator.dataset[view_index][concerned_examples, 2],\n",
    "                text=[generator.sample_ids[ind] for ind in concerned_examples],\n",
    "                hoverinfo='text',\n",
    "                legendgroup=\"Class {}\".format(lab_index),\n",
    "                mode='markers', marker=dict(size=1,\n",
    "                                            color=DEFAULT_PLOTLY_COLORS[lab_index],\n",
    "                                            opacity=0.8),\n",
    "                name=\"Class {}\".format(lab_index),\n",
    "                showlegend=show_legend),\n",
    "            row=row, col=col)\n",
    "    show_legend = False\n",
    "    col += 1\n",
    "    if col == 3:\n",
    "        col = 1\n",
    "        row += 1\n",
    "\n",
    "fig_path = os.path.join(supp_dir, \"fig.html\")\n",
    "plotly.offline.plot(fig, filename=fig_path, auto_open=False)\n",
    "IFrame(src=fig_path , width=500, height=500)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7eb1832e5e80>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"500\"\n",
       "            height=\"500\"\n",
       "            src=\"supplementary_material/fig.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The figure shows us the dataset with a 3D-subplot for each view.  It is possible to remove the samples of a specific class by clicking on a label in the legend. The sub-problems are of dimension 3 (3 features), however, to separate 3 classes only 2 features are needed, so the first two dimensions (x and y in the plots) are \"relevant\", while the third is filled with noise.  \n",
    "\n",
    "## Getting the outputted error matrix\n",
    "\n",
    "In order to measure the outputted error matrix, as the views have been generated with [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), \n",
    "the [DecisionTree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) is a good approximation of the Bayes classifier.\n",
    "\n",
    "In order to estimate the test error in the dataset for each class with a Decision Tree, we use a [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) :"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:05.088930Z",
     "start_time": "2025-07-25T16:32:05.083957Z"
    }
   },
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "folds_generator = StratifiedKFold(n_folds, random_state=random_state,\n",
    "                                 shuffle=True)\n",
    "# Splitting the array containing the indices of the samples\n",
    "folds = folds_generator.split(np.arange(generator.y.shape[0]), generator.y)\n",
    "\n",
    "# Getting the list of each the sample indices in each fold.\n",
    "folds = [[list(train), list(test)] for train, test in folds]"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Then, we get a Decision Tree of depth 3 (as each view has 3 features), and fit it on each view, for each fold.\n",
    "The ouptuted score is the cross-validation score on the 5 folds."
   ]
  },
  {
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    },
    "ExecuteTime": {
     "end_time": "2025-07-25T16:32:05.242364Z",
     "start_time": "2025-07-25T16:32:05.133795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=10)\n",
    "confusion_mat = np.zeros((n_folds, n_views, n_classes, n_classes))\n",
    "n_sample_per_class = np.zeros((n_views, n_classes, n_folds))\n",
    "\n",
    "# For each view\n",
    "for view_index in range(n_views):\n",
    "    # For each fold\n",
    "    for fold_index, [train, test] in enumerate(folds):\n",
    "\n",
    "        # Fit the decision tree on the training set\n",
    "        dt.fit(generator.dataset[view_index][train, :], generator.y[train])\n",
    "        # Predict on the testing set\n",
    "        pred = dt.predict(generator.dataset[view_index][test, :])\n",
    "\n",
    "        # Get the confusion matrix\n",
    "        confusion_mat[fold_index, view_index, :, :] = confusion_matrix(generator.y[test], pred)\n",
    "        for class_index in range(n_classes):\n",
    "            n_sample_per_class[view_index, class_index, fold_index] = np.where(generator.y[test]==class_index)[0].shape[0]\n",
    "confusion_mat = np.mean(confusion_mat, axis=0)\n",
    "n_sample_per_class = np.mean(n_sample_per_class, axis=2)\n",
    "output = np.zeros((n_classes, n_views))\n",
    "# Get the class error thanks with the confusion matrix\n",
    "for class_index in range(n_classes):\n",
    "    for view_index in range(n_views):\n",
    "        output[class_index, view_index] = 1-confusion_mat[view_index, class_index, class_index]/n_sample_per_class[view_index, class_index]\n",
    "\n",
    "print(\"Input error matrix : \\n{}\\n\\nOutputted error matrix : \\n{}\\n\\nDifference :\\n{}\".format(tabulate(error_matrix, tablefmt='grid'), tabulate(output, tablefmt='grid'), tabulate(error_matrix-output, tablefmt='grid')))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input error matrix : \n",
      "+------+------+------+------+\n",
      "| 0.3  | 0.32 | 0.38 | 0.3  |\n",
      "+------+------+------+------+\n",
      "| 0.35 | 0.28 | 0.2  | 0.15 |\n",
      "+------+------+------+------+\n",
      "| 0.25 | 0.29 | 0.15 | 0.21 |\n",
      "+------+------+------+------+\n",
      "\n",
      "Outputted error matrix : \n",
      "+----------+----------+----------+----------+\n",
      "| 0.391892 | 0.391892 | 0.385886 | 0.331832 |\n",
      "+----------+----------+----------+----------+\n",
      "| 0.297297 | 0.277778 | 0.156156 | 0.144144 |\n",
      "+----------+----------+----------+----------+\n",
      "| 0.237237 | 0.249249 | 0.168168 | 0.187688 |\n",
      "+----------+----------+----------+----------+\n",
      "\n",
      "Difference :\n",
      "+------------+-------------+-------------+-------------+\n",
      "| -0.0918919 | -0.0718919  | -0.00588589 | -0.0318318  |\n",
      "+------------+-------------+-------------+-------------+\n",
      "|  0.0527027 |  0.00222222 |  0.0438438  |  0.00585586 |\n",
      "+------------+-------------+-------------+-------------+\n",
      "|  0.0127628 |  0.0407508  | -0.0181682  |  0.0223123  |\n",
      "+------------+-------------+-------------+-------------+\n"
     ]
    }
   ],
   "execution_count": 131
  },
  {
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "cell_type": "markdown",
   "source": [
    "Here, we can see that there is a slight difference between the input error matrix and the ouput one.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this demo, we used MAGE to generate a basic multiview dataset, and we performed a naive analysis on it.\n",
    "The next tutorial will be focused on introducing redundancy, mutual error and complementarity."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
