{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Multiview Dataset Generator Demo\n",
    "\n",
    "Once you have [installed](link_ton_install) SMuDGE, you are able to run it with this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "from multiview_generator.multiple_sub_problems import MultiViewSubProblemsGenerator\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "random_state = np.random.RandomState(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Basic configuration\n",
    "\n",
    "Let us suppose that you want to build a multiview dataset with 4 views and three classes : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "name = \"demo\"\n",
    "n_views = 4\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In order to configure the dataset, you have to provide the error matrix that gives the expected error of the Byaes classifier for Class i on View j as the value in row i column j :  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+------+\n",
      "| 0.4  | 0.4 | 0.4  | 0.4  |\n",
      "+------+-----+------+------+\n",
      "| 0.55 | 0.4 | 0.4  | 0.4  |\n",
      "+------+-----+------+------+\n",
      "| 0.4  | 0.5 | 0.52 | 0.55 |\n",
      "+------+-----+------+------+\n"
     ]
    }
   ],
   "source": [
    "error_matrix = [\n",
    "   [0.4, 0.4, 0.4, 0.4],\n",
    "   [0.55, 0.4, 0.4, 0.4],\n",
    "   [0.4, 0.5, 0.52, 0.55]\n",
    "]\n",
    "print(tabulate(error_matrix, tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Once this has been defined, you can set all the other parameters of the dataset : \n",
    "* the number of samples, \n",
    "* the number of features of each view,\n",
    "* the proportion of samples in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "n_features = 3\n",
    "class_weights = [0.333, 0.333, 0.333,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate the dataset\n",
    "\n",
    "With the basic configuration done, we can generate the dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([399, 399, 399, 399]), array([299, 399, 399, 399]), array([399, 333, 319, 299])]\n",
      "400.0\n",
      "0 0 399 0\n",
      "1 0 399 0\n",
      "2 0 399 0\n",
      "3 0 399 0\n",
      "0 1 299 0\n",
      "1 1 399 0\n",
      "2 1 399 0\n",
      "3 1 399 0\n",
      "0 2 399 0\n",
      "1 2 333 0\n",
      "2 2 319 0\n",
      "3 2 299 0\n",
      "View 1 of shape (1998, 3)\n",
      "View 2 of shape (1998, 3)\n",
      "View 3 of shape (1998, 3)\n",
      "View 4 of shape (1998, 3)\n"
     ]
    }
   ],
   "source": [
    "generator = MultiViewSubProblemsGenerator(name=name, n_views=n_views, \n",
    "                                          n_classes=n_classes, \n",
    "                                          n_samples=n_samples, \n",
    "                                          n_features=n_features, \n",
    "                                          class_weights=class_weights, \n",
    "                                          error_matrix=error_matrix, \n",
    "                                          random_state=random_state)  \n",
    "\n",
    "view_data, y = generator.generate_multi_view_dataset()\n",
    "\n",
    "for view_index, view_datum in enumerate(view_data):\n",
    "    print(\"View {} of shape {}\".format(view_index+1, view_datum.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we see that the output shape is 999 instead of 1000 as the classes are supposed to be equivalent. \n",
    "\n",
    "## Get a description of it\n",
    "\n",
    "Now, if you wish to get information about the generated dataset, run : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "description = generator.gen_report(save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This will generate a markdown report on the dataset. Here, we used `save=False` so the description is not saved in a file. \n",
    "\n",
    "To print it in this notebook, we use : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Generated dataset description\n",
       "\n",
       "The dataset named `demo` has been generated by [SMuDGE](https://gitlab.lis-lab.fr/dev/multiview_generator) and is comprised of \n",
       "\n",
       "* 1998 examples, splitted in \n",
       "* 3 classes, described by \n",
       "* 4 views.\n",
       "\n",
       "The input error matrix is \n",
       " \n",
       "|         |   View 1 |   View 2 |   View 3 |   View 4 |\n",
       "|---------|----------|----------|----------|----------|\n",
       "| Class 1 |     0.4  |      0.4 |     0.4  |     0.4  |\n",
       "| Class 2 |     0.55 |      0.4 |     0.4  |     0.4  |\n",
       "| Class 3 |     0.4  |      0.5 |     0.52 |     0.55 |\n",
       "\n",
       " The classes are balanced as : \n",
       "\n",
       "* Class 1 : 666 examples (33% of the dataset)\n",
       "* Class 2 : 666 examples (33% of the dataset)\n",
       "* Class 3 : 666 examples (33% of the dataset)\n",
       "\n",
       " The views have \n",
       "\n",
       "* 0.0% redundancy, \n",
       "* 0.0% mutual error and \n",
       "* 0.0% complementarity,\n",
       "\n",
       "the remaining examples are randomly mis-labelled to fit the input error matrix.\n",
       "\n",
       "## Views description\n",
       "\n",
       "### View 1\n",
       "\n",
       "This view is generated with [`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), with the following configuration : \n",
       "```yaml\n",
       "class_sep: 10.0\n",
       "flip_y: 0\n",
       "hypercube: true\n",
       "n_clusters_per_class: 1\n",
       "n_features: 3\n",
       "n_informative: 3\n",
       "n_redundant: 0\n",
       "n_repeated: 0\n",
       "scale: 1.0\n",
       "shift: 0.0\n",
       "shuffle: false\n",
       "```\n",
       "\n",
       "### View 2\n",
       "\n",
       "This view is generated with [`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), with the following configuration : \n",
       "```yaml\n",
       "class_sep: 10.0\n",
       "flip_y: 0\n",
       "hypercube: true\n",
       "n_clusters_per_class: 1\n",
       "n_features: 3\n",
       "n_informative: 3\n",
       "n_redundant: 0\n",
       "n_repeated: 0\n",
       "scale: 1.0\n",
       "shift: 0.0\n",
       "shuffle: false\n",
       "```\n",
       "\n",
       "### View 3\n",
       "\n",
       "This view is generated with [`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), with the following configuration : \n",
       "```yaml\n",
       "class_sep: 10.0\n",
       "flip_y: 0\n",
       "hypercube: true\n",
       "n_clusters_per_class: 1\n",
       "n_features: 3\n",
       "n_informative: 3\n",
       "n_redundant: 0\n",
       "n_repeated: 0\n",
       "scale: 1.0\n",
       "shift: 0.0\n",
       "shuffle: false\n",
       "```\n",
       "\n",
       "### View 4\n",
       "\n",
       "This view is generated with [`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), with the following configuration : \n",
       "```yaml\n",
       "class_sep: 10.0\n",
       "flip_y: 0\n",
       "hypercube: true\n",
       "n_clusters_per_class: 1\n",
       "n_features: 3\n",
       "n_informative: 3\n",
       "n_redundant: 0\n",
       "n_repeated: 0\n",
       "scale: 1.0\n",
       "shift: 0.0\n",
       "shuffle: false\n",
       "```\n",
       "\n",
       "This report has been automatically generated on April 22, 2020 at 09:19:24"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display,Markdown\n",
    "display(Markdown(description))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "But if you just want to save it, you can use : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "generator.gen_report(output_path=\"supplementary_material\", save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This will save the description in the current directory, in a file called `demo.md` as the name of the dataset is \"demo\".\n",
    "\n",
    "## Save it in an HDF5 file \n",
    "\n",
    "Moreover, it is possible to save tha dataset in an HDF5 file, compatible with [SuMMIT](https://gitlab.lis-lab.fr/baptiste.bauvin/summit/) with \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "generator.to_hdf5_mc(saving_path='supplementary_material')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualizing the dataset with [plotly](https://plotly.com/)\n",
    "\n",
    "Here, we purposely used ony 3 featrues per view, so the generated dataset is easily plottable in 3D. \n",
    "\n",
    "Let us plot each view : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "\n",
    "fig = make_subplots(rows=2, cols=2,\n",
    "                    subplot_titles= [\"View {}\".format(view_index) \n",
    "                                     for view_index in range(n_views)],\n",
    "                    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}, ],\n",
    "                               [{'type': 'scatter3d'},\n",
    "                                {'type': 'scatter3d'}, ]])\n",
    "row = 1\n",
    "col = 1\n",
    "show_legend = True\n",
    "# Plot the data for each view and each label\n",
    "for view_index in range(n_views):\n",
    "    for lab_index in range(n_classes):\n",
    "        concerned_examples = np.where(generator.y == lab_index)[0]\n",
    "        fig.add_trace(\n",
    "            go.Scatter3d(\n",
    "                x=generator.view_data[view_index][concerned_examples, 0],\n",
    "                y=generator.view_data[view_index][concerned_examples, 1],\n",
    "                z=generator.view_data[view_index][concerned_examples, 2],\n",
    "                text=[generator.example_ids[ind] for ind in concerned_examples],\n",
    "                hoverinfo='text',\n",
    "                legendgroup=\"Class {}\".format(lab_index),\n",
    "                mode='markers', marker=dict(size=1,\n",
    "                                            color=DEFAULT_PLOTLY_COLORS[lab_index],\n",
    "                                            opacity=0.8), \n",
    "                name=\"Class {}\".format(lab_index), \n",
    "                showlegend=show_legend),\n",
    "            row=row, col=col)\n",
    "    show_legend = False\n",
    "    col += 1\n",
    "    if col == 3:\n",
    "        col = 1\n",
    "        row += 1\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The figure shows us the dataset with a 3D-subplot for each view.  It is possible to remove the samples of a specific class by clicking on a label in the legend.\n",
    "\n",
    "## Getting the outputted error matrix\n",
    "\n",
    "In order to measure the outputted error matrix, as the views have been generated with [make_classification](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html), \n",
    "the [DecisionTree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) is a good approximation of the Bayes classifier.\n",
    "\n",
    "In order to estimate the test error in the dataset for each class with a Decision Tree, we use a [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "folds_generator = StratifiedKFold(n_folds, random_state=random_state,\n",
    "                                 shuffle=True)\n",
    "# Splitting the array containing the indices of the samples\n",
    "folds = folds_generator.split(np.arange(generator.y.shape[0]), generator.y)\n",
    "\n",
    "# Getting the list of each the sample indices in each fold.\n",
    "folds = [[list(train), list(test)] for train, test in folds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, we get a Decision Tree of depth 3 (as each view has 3 features), and fit it on each view, for each fold. \n",
    "The ouptuted score is the cross-validation score on the 5 folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input error matrix : \n",
      "+------+-----+------+------+\n",
      "| 0.4  | 0.4 | 0.4  | 0.4  |\n",
      "+------+-----+------+------+\n",
      "| 0.55 | 0.4 | 0.4  | 0.4  |\n",
      "+------+-----+------+------+\n",
      "| 0.4  | 0.5 | 0.52 | 0.55 |\n",
      "+------+-----+------+------+\n",
      "\n",
      "Outputted error matrix : \n",
      "+----------+----------+----------+----------+\n",
      "| 0.402402 | 0.40991  | 0.411411 | 0.436937 |\n",
      "+----------+----------+----------+----------+\n",
      "| 0.54955  | 0.403904 | 0.405405 | 0.43994  |\n",
      "+----------+----------+----------+----------+\n",
      "| 0.442943 | 0.504505 | 0.534535 | 0.542042 |\n",
      "+----------+----------+----------+----------+\n",
      "\n",
      "Difference :\n",
      "+-------------+-------------+-------------+-------------+\n",
      "| -0.0024024  | -0.00990991 | -0.0114114  | -0.0369369  |\n",
      "+-------------+-------------+-------------+-------------+\n",
      "|  0.00045045 | -0.0039039  | -0.00540541 | -0.0399399  |\n",
      "+-------------+-------------+-------------+-------------+\n",
      "| -0.0429429  | -0.0045045  | -0.0145345  |  0.00795796 |\n",
      "+-------------+-------------+-------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "confusion_mat = np.zeros((n_folds, n_views, n_classes, n_classes))\n",
    "n_sample_per_class = np.zeros((n_views, n_classes, n_folds))\n",
    "\n",
    "# For each view\n",
    "for view_index in range(n_views):\n",
    "    # For each fold \n",
    "    for fold_index, [train, test] in enumerate(folds):\n",
    "        \n",
    "        # Fit the decision tree on the training set\n",
    "        dt.fit(generator.view_data[view_index][train, :], generator.y[train])\n",
    "        \n",
    "        # Predict on the testing set\n",
    "        pred = dt.predict(generator.view_data[view_index][test, :])\n",
    "        \n",
    "        # Get the confusion matrix\n",
    "        confusion_mat[fold_index, view_index, :, :] = confusion_matrix(generator.y[test], pred)\n",
    "        for class_index in range(n_classes):\n",
    "            n_sample_per_class[view_index, class_index, fold_index] = np.where(generator.y[test]==class_index)[0].shape[0]\n",
    "confusion_mat = np.mean(confusion_mat, axis=0)\n",
    "n_sample_per_class = np.mean(n_sample_per_class, axis=2)\n",
    "output = np.zeros((n_classes, n_views))\n",
    "# Get the class error thanks with the confusion matrix\n",
    "for class_index in range(n_classes):\n",
    "    for view_index in range(n_views):\n",
    "        output[class_index, view_index] = 1-confusion_mat[view_index, class_index, class_index]/n_sample_per_class[view_index, class_index]\n",
    "        \n",
    "print(\"Input error matrix : \\n{}\\n\\nOutputted error matrix : \\n{}\\n\\nDifference :\\n{}\".format(tabulate(error_matrix, tablefmt='grid'), tabulate(output, tablefmt='grid'), tabulate(error_matrix-output, tablefmt='grid')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Here, we can see that there is a slight difference between the input error matrix and the ouput one.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "In this demo, we used SMuDGE to generate a basic multiview dataset, and we performed a naive analysis on it. \n",
    "The next tutorial will be focused on introducing redundancy, mutual error and complementarity. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
